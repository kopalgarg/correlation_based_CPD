{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from scipy.io import arff\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "from scipy.special import expit\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train_df.csv\",low_memory=False)\n",
    "test_df = pd.read_csv(\"test_df.csv\",low_memory=False)\n",
    "val_df = pd.read_csv(\"val_df.csv\",low_memory=False)\n",
    "\n",
    "all_columns = [\"awake\",\"breath_average\", \"deep\", \"duration\", \"hr_average\", \"hr_lowest\",\n",
    "          \"light\", \"rem\", \"restless\", \"temperature_delta\",\n",
    "          \"total\", \"rmssd\"]\n",
    "\n",
    "\n",
    "train_df = train_df[all_columns]\n",
    "test_df = test_df[all_columns]\n",
    "val_df = val_df[all_columns]\n",
    "train_df = train_df.fillna(method='ffill')\n",
    "test_df = test_df.fillna(method='ffill')\n",
    "val_df = val_df.fillna(method='ffill')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_df_n = MinMaxScaler().fit_transform(train_df.values)\n",
    "train_df = pd.DataFrame(train_df_n)\n",
    "test_df_n = MinMaxScaler().fit_transform(test_df.values)\n",
    "test_df = pd.DataFrame(test_df_n)\n",
    "val_df_n = MinMaxScaler().fit_transform(val_df.values)\n",
    "val_df = pd.DataFrame(val_df_n)\n",
    "\n",
    "train_df.columns = all_columns\n",
    "test_df.columns = all_columns\n",
    "val_df.columns = all_columns\n",
    "print('done')\n",
    "\n",
    "import numpy as np\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n",
    "\n",
    "dataset = train_df.values\n",
    "# choose a number of time steps\n",
    "n_steps = 30\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "\n",
    "n_features = X.shape[2]\n",
    "print(n_features)\n",
    "\n",
    "dataset_test = test_df.values\n",
    "X_test, y_test = split_sequences(dataset_test, n_steps)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "# define model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(320,input_shape=(n_steps, n_features), return_sequences=True))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.5)) \n",
    "model.add(tf.keras.layers.LSTM(200, return_sequences=True))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.5)) \n",
    "model.add(tf.keras.layers.Dropout(0.3)) \n",
    "model.add(tf.keras.layers.LSTM(120, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(0.2)) \n",
    "model.add(tf.keras.layers.LSTM(40, return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(0.2)) \n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=2)\n",
    "yhat = model.predict(X)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plot \n",
    "f, (ax1) = plt.subplots(1, 1 ,sharex='col')\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(16)\n",
    "ax1.plot(y[100:200])\n",
    "ax1.plot(yhat[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('time_series_explainability': conda)",
   "language": "python",
   "name": "python395jvsc74a57bd0a8bab15b8390494538736be73eaebd9e09ab677c4d87a212cb0b186072fe5e1d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "a8bab15b8390494538736be73eaebd9e09ab677c4d87a212cb0b186072fe5e1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
